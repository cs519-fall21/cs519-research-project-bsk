From c81a77210fee917f40df440ab73b6a55a950e9a2 Mon Sep 17 00:00:00 2001
From: kartikmodi <kartik.modi@rutgers.edu>
Date: Sat, 6 Nov 2021 15:12:17 -0400
Subject: [PATCH 1/3] revision 3

---
 arch/x86/entry/syscalls/syscall_64.tbl |   2 +-
 include/linux/mm_types.h               |  17 +++
 include/linux/sched.h                  |   5 +-
 include/linux/syscalls.h               |   1 +
 mm/memory.c                            | 162 +++++++++++++++++++++++--
 mm/mmap.c                              |  12 +-
 6 files changed, 188 insertions(+), 11 deletions(-)

diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index 4dfe42666d0c..e8f5c9f3bc23 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -341,7 +341,7 @@
 330	common	pkey_alloc		__x64_sys_pkey_alloc
 331	common	pkey_free		__x64_sys_pkey_free
 332	common	statx			__x64_sys_statx
-
+333	common  fallos                  sys_fallos
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
 # for native 64-bit operation. The __x32_compat_sys stubs are created
diff --git a/include/linux/mm_types.h b/include/linux/mm_types.h
index 21612347d311..5baceb5a8561 100644
--- a/include/linux/mm_types.h
+++ b/include/linux/mm_types.h
@@ -652,4 +652,21 @@ typedef struct {
 	unsigned long val;
 } swp_entry_t;
 
+typedef struct fallOS_extent_list {
+	unsigned long fallOS_extent_frame_addr;
+	struct list_head fallOS_extent_pcp_list;
+} fallOS_extent_list_t;
+
+typedef struct fallOS_extent {
+	struct rb_node fallOS_rb_node;
+	int fallOS_extent_id;
+	unsigned int fallOS_extent_pcp_count;
+	unsigned long fallOS_virt_start;
+	unsigned long fallOS_extent_start;
+	unsigned long fallOS_extent_end;
+	struct list_head fallOS_extent_pcp_head;
+} fallOS_extent_t;
+
+#define FALLOS_TASK_EXTENT_S sizeof(fallOS_extent_t)
+#define FALLOS_EXTENT_LIST_S sizeof(fallOS_extent_list_t)
 #endif /* _LINUX_MM_TYPES_H */
diff --git a/include/linux/sched.h b/include/linux/sched.h
index ca3f3eae8980..a4effe83a6f8 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1167,7 +1167,10 @@ struct task_struct {
 	/* Used by LSM modules for access restriction: */
 	void				*security;
 #endif
-
+	int fallOS_extent;
+	struct rb_root fallOS_extent_rb;
+	int fallOS_extent_count;
+	//struct fallOS_extent *fallOS_task_extent;
 	/*
 	 * New fields for task_struct should be added above here, so that
 	 * they are included in the randomized portion of task_struct.
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 70fcda1a9049..6e533fd58f97 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1268,4 +1268,5 @@ static inline long ksys_truncate(const char __user *pathname, loff_t length)
 	return do_sys_truncate(pathname, length);
 }
 
+asmlinkage long sys_fallos(void);
 #endif
diff --git a/mm/memory.c b/mm/memory.c
index 01f5464e0fd2..76398da105be 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -127,7 +127,6 @@ unsigned long zero_pfn __read_mostly;
 EXPORT_SYMBOL(zero_pfn);
 
 unsigned long highest_memmap_pfn __read_mostly;
-
 /*
  * CONFIG_MMU architectures set up ZERO_PAGE in their paging_init()
  */
@@ -3095,11 +3094,137 @@ int do_swap_page(struct vm_fault *vmf)
 	return ret;
 }
 
+/*
+rb code to maintain extent
+*/
+/*static fallOS_extent_t* find_extent_in_fallOS_extent_rb(unsigned long frame_addr) {
+	struct rb_node *node = current->fallOS_extent_rb.rb_node;
+	fallOS_extent_t *extent;
+	while(node) {
+		extent = rb_entry(node, fallOS_extent_t, fallOS_rb_node);
+		if (extent->fallOS_extent_start > frame_addr)
+			node = node->rb_left;
+		else if (extent->fallOS_extent_end < frame_addr)
+			node = node->rb_right;
+		else
+			return extent;
+	}
+	return NULL;
+}*/
+
+#define FALLOS_CAN_MERGE_RB(page_start, start_value, end_value) \
+	(start_value ? ((page_start + PAGE_SIZE) == start_value) \
+	: (end_value + 1 == page_start))
+//fallOS_rb_node
+
+static int fallOS_add_page_to_extent(struct page *page, fallOS_extent_t *extent, unsigned long addr);
+static fallOS_extent_t* fallOS_add_extent(struct page *page, unsigned long addr);
+
+void merge_rb_nodes(struct page *page, fallOS_extent_t *extent, unsigned long addr) {
+	fallOS_add_page_to_extent(page, extent, addr);
+	/*add code to merge old children present in the tree*/
+}
+static int fallOS_addto_extent_rb(struct rb_node **node, struct page *page, struct rb_node *parent, unsigned long virtual_addr) {
+	fallOS_extent_t *rb_extent;
+	unsigned long phys_addr;
+	unsigned long virt_end_offset;
+	phys_addr = virt_to_phys(page_address(page));
+	if (*node) {
+		rb_extent = rb_entry(*node, fallOS_extent_t, fallOS_rb_node);
+		if (!rb_extent) {
+			printk("fallOS MAY CRASH returning\n");
+			return 0;
+		}
+		virt_end_offset = (rb_extent->fallOS_extent_pcp_count * PAGE_SIZE) - 1;
+		if (rb_extent->fallOS_extent_start > phys_addr) {
+			if (FALLOS_CAN_MERGE_RB(phys_addr, (rb_extent->fallOS_extent_start), 0) && 
+			    FALLOS_CAN_MERGE_RB(virtual_addr, (rb_extent->fallOS_virt_start), 0))
+				merge_rb_nodes(page, rb_extent, virtual_addr);
+			else
+				fallOS_addto_extent_rb(&((*node)->rb_left), page, *node, virtual_addr);
+		} else if(rb_extent->fallOS_extent_end < phys_addr) {
+			if (FALLOS_CAN_MERGE_RB(phys_addr, 0, (rb_extent->fallOS_extent_end)) && 
+	FALLOS_CAN_MERGE_RB(virtual_addr, 0, (rb_extent->fallOS_virt_start + virt_end_offset)))
+				merge_rb_nodes(page, rb_extent, virtual_addr);
+			else
+				fallOS_addto_extent_rb(&((*node)->rb_right), page, *node, virtual_addr);
+		} else
+			printk("fallOS frame already present\n");
+	} else {
+		if((rb_extent = fallOS_add_extent(page, virtual_addr)) == NULL)
+			return 0;
+		rb_link_node((struct rb_node *)rb_extent, parent, node);
+		rb_insert_color((struct rb_node *)rb_extent, &(current->fallOS_extent_rb));
+		//*node = &(rb_extent->fallOS_rb_node);
+	}
+	return 1;
+}
+
+/*
+extent code for pages
+*/
+#define CHECK_EXTENT_START(frame_addr, extent_start) \
+	((!extent_start) || (frame_addr < extent_start))
+#define CHECK_EXTENT_END(frame_addr, extent_end) \
+	((!extent_end) || (frame_addr > extent_end))
+
+static int fallOS_add_page_to_extent(struct page *page, fallOS_extent_t *extent, unsigned long addr) {
+        static int extent_id = 0;
+	fallOS_extent_list_t *page_extent;
+	unsigned long phys_addr;
+	phys_addr = virt_to_phys(page_address(page));
+	page_extent = kmalloc(FALLOS_EXTENT_LIST_S, GFP_KERNEL);
+	if (!page_extent)
+		return 0;
+	page_extent->fallOS_extent_frame_addr = phys_addr; 
+	INIT_LIST_HEAD(&(page_extent->fallOS_extent_pcp_list));
+        if (extent->fallOS_extent_id < 0)
+                extent->fallOS_extent_id = ++extent_id;
+        extent->fallOS_extent_pcp_count++;
+        if (CHECK_EXTENT_START(phys_addr, (extent->fallOS_extent_start))) {
+                extent->fallOS_extent_start = phys_addr;
+		extent->fallOS_virt_start = addr;
+	}
+        if (CHECK_EXTENT_END(phys_addr, (extent->fallOS_extent_end))) 
+                extent->fallOS_extent_end = phys_addr + PAGE_SIZE - 1;
+        list_add(&(page_extent->fallOS_extent_pcp_list), &(extent->fallOS_extent_pcp_head));
+	return 1; 
+}
+
+void fallOS_initialize_extent(fallOS_extent_t *extent) {
+	extent->fallOS_extent_start = 0;
+	extent->fallOS_extent_end = 0;
+	extent->fallOS_extent_pcp_count = 0;
+	extent->fallOS_extent_id = -1;
+	extent->fallOS_virt_start = 0;
+	extent->fallOS_rb_node.rb_left = NULL;
+	extent->fallOS_rb_node.rb_right = NULL;
+	INIT_LIST_HEAD(&(extent->fallOS_extent_pcp_head));
+}
+
+static fallOS_extent_t* fallOS_add_extent(struct page *page, unsigned long addr) {
+	fallOS_extent_t *extent;
+        extent = kmalloc(FALLOS_TASK_EXTENT_S, GFP_KERNEL);
+	if (!extent)
+		return NULL;
+	fallOS_initialize_extent(extent);
+        if (!fallOS_add_page_to_extent(page, extent, addr))
+		return NULL;
+        /*printk("fallOS Following are details:\n");
+        printk("fallOS extent start addr: %lu\textent end addr: %lu\textent count: %d\ntpid: %d\n", 
+		   extent->fallOS_extent_start, extent->fallOS_extent_end, 
+		   extent->fallOS_extent_pcp_count, current->fallOS_extent);*/
+	current->fallOS_extent_count++;
+	printk("fallOS extent count %d\n", current->fallOS_extent_count);
+        return extent;
+}
 /*
  * We enter with non-exclusive mmap_sem (to exclude vma changes,
  * but allow concurrent faults), and pte mapped but not yet locked.
  * We return with mmap_sem still held, but pte unmapped and unlocked.
  */
+/*int fallOS_adjust_extent(struct page *page);
+int fallOS_add_to_extent(fallOS_extent_list_t *page_extent, fallOS_extent_t *extent);*/
 static int do_anonymous_page(struct vm_fault *vmf)
 {
 	struct vm_area_struct *vma = vmf->vma;
@@ -3107,11 +3232,9 @@ static int do_anonymous_page(struct vm_fault *vmf)
 	struct page *page;
 	int ret = 0;
 	pte_t entry;
-
 	/* File mapping without ->vm_ops ? */
 	if (vma->vm_flags & VM_SHARED)
 		return VM_FAULT_SIGBUS;
-
 	/*
 	 * Use pte_alloc() instead of pte_alloc_map().  We can't run
 	 * pte_offset_map() on pmds where a huge pmd might be created
@@ -3153,9 +3276,20 @@ static int do_anonymous_page(struct vm_fault *vmf)
 	if (unlikely(anon_vma_prepare(vma)))
 		goto oom;
 	page = alloc_zeroed_user_highpage_movable(vma, vmf->address);
+	if (current->pid == current->fallOS_extent){
+		printk("print page struct with percent p %p",page);
+		printk("print page struct with percent llu %llu",page);
+		printk("print page struct with percent d %d",page);
+		printk("print page_to_phys with percent p %p",page_to_phys(page));
+		printk("print page_to_phys with percent d %d",page_to_phys(page));
+		printk("print page_to_phys with percent llu %llu",page_to_phys(page));
+	}
 	if (!page)
 		goto oom;
-
+	if (current->pid == current->fallOS_extent) {
+		printk("virtual address: %lu page physical: %llu", vmf->address, virt_to_phys(page_address(page)));
+		fallOS_addto_extent_rb(&(current->fallOS_extent_rb.rb_node), page, current->fallOS_extent_rb.rb_node, vmf->address);
+	}
 	if (mem_cgroup_try_charge(page, vma->vm_mm, GFP_KERNEL, &memcg, false))
 		goto oom_free_page;
 
@@ -3918,7 +4052,10 @@ static int wp_huge_pud(struct vm_fault *vmf, pud_t orig_pud)
  */
 static int handle_pte_fault(struct vm_fault *vmf)
 {
+	int ret_code = 0;
 	pte_t entry;
+	int index;
+	unsigned long initial_addr;
 
 	if (unlikely(pmd_none(*vmf->pmd))) {
 		/*
@@ -3955,10 +4092,21 @@ static int handle_pte_fault(struct vm_fault *vmf)
 			vmf->pte = NULL;
 		}
 	}
-
 	if (!vmf->pte) {
-		if (vma_is_anonymous(vmf->vma))
-			return do_anonymous_page(vmf);
+		if (vma_is_anonymous(vmf->vma)) {
+			ret_code = do_anonymous_page(vmf);
+			if (current->pid == current->fallOS_extent) {
+				initial_addr = vmf->address;
+				for (index = 1; index < 3; index++) {
+					if (initial_addr + index * PAGE_SIZE < vmf->vma->vm_end) {
+						vmf->address = initial_addr + index * PAGE_SIZE;
+						ret_code = do_anonymous_page(vmf);
+					}
+				}	
+				vmf->address = initial_addr;
+			}
+			return ret_code;
+		}
 		else
 			return do_fault(vmf);
 	}
diff --git a/mm/mmap.c b/mm/mmap.c
index fc41c0543d7f..fce17e582c5c 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -45,7 +45,7 @@
 #include <linux/moduleparam.h>
 #include <linux/pkeys.h>
 #include <linux/oom.h>
-
+#include <linux/sched.h>
 #include <linux/uaccess.h>
 #include <asm/cacheflush.h>
 #include <asm/tlb.h>
@@ -67,7 +67,6 @@ const int mmap_rnd_compat_bits_min = CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MIN;
 const int mmap_rnd_compat_bits_max = CONFIG_ARCH_MMAP_RND_COMPAT_BITS_MAX;
 int mmap_rnd_compat_bits __read_mostly = CONFIG_ARCH_MMAP_RND_COMPAT_BITS;
 #endif
-
 static bool ignore_rlimit_data;
 core_param(ignore_rlimit_data, ignore_rlimit_data, bool, 0644);
 
@@ -3722,4 +3721,13 @@ static int __meminit init_reserve_notifier(void)
 
 	return 0;
 }
+asmlinkage long sys_fallos(void) {
+	struct task_struct *tsk;
+	tsk = get_current();
+	tsk->fallOS_extent = tsk->pid;
+	tsk->fallOS_extent_rb = RB_ROOT;
+	tsk->fallOS_extent_count = 0;
+	return 0;
+}
+
 subsys_initcall(init_reserve_notifier);
-- 
2.33.0


From 628048b556b53a08a3261fd0a12b15e6b21fa4fc Mon Sep 17 00:00:00 2001
From: kartikmodi <kartik.modi@rutgers.edu>
Date: Mon, 8 Nov 2021 15:05:15 -0500
Subject: [PATCH 2/3] Performance testing and benchmark changes

---
 arch/x86/entry/syscalls/syscall_64.tbl |  1 +
 include/linux/sched.h                  |  1 +
 include/linux/syscalls.h               |  1 +
 mm/memory.c                            | 46 ++++++++++++++++++++------
 mm/mmap.c                              | 11 ++++++
 5 files changed, 49 insertions(+), 11 deletions(-)

diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index e8f5c9f3bc23..70f1afeb11e2 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -342,6 +342,7 @@
 331	common	pkey_free		__x64_sys_pkey_free
 332	common	statx			__x64_sys_statx
 333	common  fallos                  sys_fallos
+334	common	total_ext_count		sys_total_ext_count
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
 # for native 64-bit operation. The __x32_compat_sys stubs are created
diff --git a/include/linux/sched.h b/include/linux/sched.h
index a4effe83a6f8..ffabca1f9213 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1168,6 +1168,7 @@ struct task_struct {
 	void				*security;
 #endif
 	int fallOS_extent;
+	int fallOS_total_extent_count;
 	struct rb_root fallOS_extent_rb;
 	int fallOS_extent_count;
 	//struct fallOS_extent *fallOS_task_extent;
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 6e533fd58f97..5ca1e54ba4ba 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1269,4 +1269,5 @@ static inline long ksys_truncate(const char __user *pathname, loff_t length)
 }
 
 asmlinkage long sys_fallos(void);
+asmlinkage int sys_total_ext_count(void);
 #endif
diff --git a/mm/memory.c b/mm/memory.c
index 76398da105be..5ccb88545c2a 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -3097,20 +3097,33 @@ int do_swap_page(struct vm_fault *vmf)
 /*
 rb code to maintain extent
 */
-/*static fallOS_extent_t* find_extent_in_fallOS_extent_rb(unsigned long frame_addr) {
-	struct rb_node *node = current->fallOS_extent_rb.rb_node;
+static int find_total_extent_count_in_fallOS(struct rb_node *node, int total_pcp) {
+	//struct rb_node *node = current->fallOS_extent_rb.rb_node;
 	fallOS_extent_t *extent;
-	while(node) {
-		extent = rb_entry(node, fallOS_extent_t, fallOS_rb_node);
-		if (extent->fallOS_extent_start > frame_addr)
+	//int total_pcp;
+	//while(node) {
+	total_pcp = 0;
+	//printk("Inside find extent count");
+	if(node == NULL){
+		return 0;
+	}
+	extent = rb_entry(node, fallOS_extent_t, fallOS_rb_node);
+	printk("Extent Start %lu , Extent End %lu",extent->fallOS_extent_start,extent->fallOS_extent_end);
+
+	if(node->rb_left)
+		total_pcp+=find_total_extent_count_in_fallOS(node->rb_left,total_pcp);
+	total_pcp = total_pcp + extent->fallOS_extent_pcp_count;
+	//printk("CNNNT %d",total_pcp);
+	if(node->rb_right)
+		total_pcp += find_total_extent_count_in_fallOS(node->rb_right,total_pcp);
+		/*if (extent->fallOS_extent_start > frame_addr)
 			node = node->rb_left;
 		else if (extent->fallOS_extent_end < frame_addr)
 			node = node->rb_right;
 		else
-			return extent;
-	}
-	return NULL;
-}*/
+			return extent;*/
+	return total_pcp;
+}
 
 #define FALLOS_CAN_MERGE_RB(page_start, start_value, end_value) \
 	(start_value ? ((page_start + PAGE_SIZE) == start_value) \
@@ -3181,6 +3194,7 @@ static int fallOS_add_page_to_extent(struct page *page, fallOS_extent_t *extent,
         if (extent->fallOS_extent_id < 0)
                 extent->fallOS_extent_id = ++extent_id;
         extent->fallOS_extent_pcp_count++;
+	//printk("PCP count :%d",extent->fallOS_extent_pcp_count);
         if (CHECK_EXTENT_START(phys_addr, (extent->fallOS_extent_start))) {
                 extent->fallOS_extent_start = phys_addr;
 		extent->fallOS_virt_start = addr;
@@ -3215,7 +3229,7 @@ static fallOS_extent_t* fallOS_add_extent(struct page *page, unsigned long addr)
 		   extent->fallOS_extent_start, extent->fallOS_extent_end, 
 		   extent->fallOS_extent_pcp_count, current->fallOS_extent);*/
 	current->fallOS_extent_count++;
-	printk("fallOS extent count %d\n", current->fallOS_extent_count);
+	//printk("fallOS extent count %d\n", current->fallOS_extent_count);
         return extent;
 }
 /*
@@ -4096,8 +4110,9 @@ static int handle_pte_fault(struct vm_fault *vmf)
 		if (vma_is_anonymous(vmf->vma)) {
 			ret_code = do_anonymous_page(vmf);
 			if (current->pid == current->fallOS_extent) {
+				printk("fallOS");
 				initial_addr = vmf->address;
-				for (index = 1; index < 3; index++) {
+				for (index = 1; index < 6; index++) {
 					if (initial_addr + index * PAGE_SIZE < vmf->vma->vm_end) {
 						vmf->address = initial_addr + index * PAGE_SIZE;
 						ret_code = do_anonymous_page(vmf);
@@ -4105,6 +4120,15 @@ static int handle_pte_fault(struct vm_fault *vmf)
 				}	
 				vmf->address = initial_addr;
 			}
+			if(current->pid == current->fallOS_total_extent_count){
+		 		/* syscall to count total extent ? */
+				printk("INSIDETOTAL");
+				int total_pcp;
+				total_pcp = 0;
+				printk("Total Page Count %d", find_total_extent_count_in_fallOS(current->fallOS_extent_rb.rb_node,total_pcp));
+				printk("fallOS extent count %d\n", current->fallOS_extent_count);
+				current->fallOS_total_extent_count = 0;
+			}
 			return ret_code;
 		}
 		else
diff --git a/mm/mmap.c b/mm/mmap.c
index fce17e582c5c..95df4a976703 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -3722,6 +3722,7 @@ static int __meminit init_reserve_notifier(void)
 	return 0;
 }
 asmlinkage long sys_fallos(void) {
+	printk("IN SYSFALLOS");
 	struct task_struct *tsk;
 	tsk = get_current();
 	tsk->fallOS_extent = tsk->pid;
@@ -3730,4 +3731,14 @@ asmlinkage long sys_fallos(void) {
 	return 0;
 }
 
+asmlinkage int sys_total_ext_count(void){
+
+	printk("IN SYSTOTALEXT");
+	struct task_struct *tsk;
+        tsk = get_current();
+        tsk->fallOS_total_extent_count = tsk->pid;
+	return 0;
+
+}
+
 subsys_initcall(init_reserve_notifier);
-- 
2.33.0


From ea50da2f15afaff58437fb59387133f1391538c4 Mon Sep 17 00:00:00 2001
From: kartikmodi <kartik.modi@rutgers.edu>
Date: Mon, 8 Nov 2021 17:29:01 -0500
Subject: [PATCH 3/3] Moving to logical address mapping rbtree from physical

---
 arch/x86/entry/syscalls/syscall_64.tbl |  2 +-
 include/linux/sched.h                  |  2 +-
 include/linux/syscalls.h               |  2 +-
 mm/memory.c                            | 77 ++++++++------------------
 mm/mmap.c                              |  6 +-
 5 files changed, 27 insertions(+), 62 deletions(-)

diff --git a/arch/x86/entry/syscalls/syscall_64.tbl b/arch/x86/entry/syscalls/syscall_64.tbl
index 70f1afeb11e2..bb12f10efafb 100644
--- a/arch/x86/entry/syscalls/syscall_64.tbl
+++ b/arch/x86/entry/syscalls/syscall_64.tbl
@@ -342,7 +342,7 @@
 331	common	pkey_free		__x64_sys_pkey_free
 332	common	statx			__x64_sys_statx
 333	common  fallos                  sys_fallos
-334	common	total_ext_count		sys_total_ext_count
+334	common  traverse		sys_traverse
 #
 # x32-specific system call numbers start at 512 to avoid cache impact
 # for native 64-bit operation. The __x32_compat_sys stubs are created
diff --git a/include/linux/sched.h b/include/linux/sched.h
index ffabca1f9213..aa28340d73b1 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1168,9 +1168,9 @@ struct task_struct {
 	void				*security;
 #endif
 	int fallOS_extent;
-	int fallOS_total_extent_count;
 	struct rb_root fallOS_extent_rb;
 	int fallOS_extent_count;
+	int traverse;
 	//struct fallOS_extent *fallOS_task_extent;
 	/*
 	 * New fields for task_struct should be added above here, so that
diff --git a/include/linux/syscalls.h b/include/linux/syscalls.h
index 5ca1e54ba4ba..80cbd0cf0059 100644
--- a/include/linux/syscalls.h
+++ b/include/linux/syscalls.h
@@ -1269,5 +1269,5 @@ static inline long ksys_truncate(const char __user *pathname, loff_t length)
 }
 
 asmlinkage long sys_fallos(void);
-asmlinkage int sys_total_ext_count(void);
+asmlinkage long sys_traverse(void);
 #endif
diff --git a/mm/memory.c b/mm/memory.c
index 5ccb88545c2a..3bb7d2922fcd 100644
--- a/mm/memory.c
+++ b/mm/memory.c
@@ -3097,38 +3097,23 @@ int do_swap_page(struct vm_fault *vmf)
 /*
 rb code to maintain extent
 */
-static int find_total_extent_count_in_fallOS(struct rb_node *node, int total_pcp) {
-	//struct rb_node *node = current->fallOS_extent_rb.rb_node;
+
+static void find_pcp_count(struct rb_node *node, unsigned int *count) {
 	fallOS_extent_t *extent;
-	//int total_pcp;
-	//while(node) {
-	total_pcp = 0;
-	//printk("Inside find extent count");
-	if(node == NULL){
-		return 0;
-	}
+	if (node == NULL)
+		return;
 	extent = rb_entry(node, fallOS_extent_t, fallOS_rb_node);
-	printk("Extent Start %lu , Extent End %lu",extent->fallOS_extent_start,extent->fallOS_extent_end);
-
-	if(node->rb_left)
-		total_pcp+=find_total_extent_count_in_fallOS(node->rb_left,total_pcp);
-	total_pcp = total_pcp + extent->fallOS_extent_pcp_count;
-	//printk("CNNNT %d",total_pcp);
-	if(node->rb_right)
-		total_pcp += find_total_extent_count_in_fallOS(node->rb_right,total_pcp);
-		/*if (extent->fallOS_extent_start > frame_addr)
-			node = node->rb_left;
-		else if (extent->fallOS_extent_end < frame_addr)
-			node = node->rb_right;
-		else
-			return extent;*/
-	return total_pcp;
+	if (extent == NULL)
+		return;
+	*count += extent->fallOS_extent_pcp_count;
+	find_pcp_count(node->rb_left, count);
+	find_pcp_count(node->rb_right, count);
+	return;
 }
 
 #define FALLOS_CAN_MERGE_RB(page_start, start_value, end_value) \
 	(start_value ? ((page_start + PAGE_SIZE) == start_value) \
 	: (end_value + 1 == page_start))
-//fallOS_rb_node
 
 static int fallOS_add_page_to_extent(struct page *page, fallOS_extent_t *extent, unsigned long addr);
 static fallOS_extent_t* fallOS_add_extent(struct page *page, unsigned long addr);
@@ -3149,13 +3134,13 @@ static int fallOS_addto_extent_rb(struct rb_node **node, struct page *page, stru
 			return 0;
 		}
 		virt_end_offset = (rb_extent->fallOS_extent_pcp_count * PAGE_SIZE) - 1;
-		if (rb_extent->fallOS_extent_start > phys_addr) {
+		if (rb_extent->fallOS_virt_start > virtual_addr) {
 			if (FALLOS_CAN_MERGE_RB(phys_addr, (rb_extent->fallOS_extent_start), 0) && 
 			    FALLOS_CAN_MERGE_RB(virtual_addr, (rb_extent->fallOS_virt_start), 0))
 				merge_rb_nodes(page, rb_extent, virtual_addr);
 			else
 				fallOS_addto_extent_rb(&((*node)->rb_left), page, *node, virtual_addr);
-		} else if(rb_extent->fallOS_extent_end < phys_addr) {
+		} else if(rb_extent->fallOS_virt_start + virt_end_offset < virtual_addr) {
 			if (FALLOS_CAN_MERGE_RB(phys_addr, 0, (rb_extent->fallOS_extent_end)) && 
 	FALLOS_CAN_MERGE_RB(virtual_addr, 0, (rb_extent->fallOS_virt_start + virt_end_offset)))
 				merge_rb_nodes(page, rb_extent, virtual_addr);
@@ -3168,7 +3153,6 @@ static int fallOS_addto_extent_rb(struct rb_node **node, struct page *page, stru
 			return 0;
 		rb_link_node((struct rb_node *)rb_extent, parent, node);
 		rb_insert_color((struct rb_node *)rb_extent, &(current->fallOS_extent_rb));
-		//*node = &(rb_extent->fallOS_rb_node);
 	}
 	return 1;
 }
@@ -3194,7 +3178,6 @@ static int fallOS_add_page_to_extent(struct page *page, fallOS_extent_t *extent,
         if (extent->fallOS_extent_id < 0)
                 extent->fallOS_extent_id = ++extent_id;
         extent->fallOS_extent_pcp_count++;
-	//printk("PCP count :%d",extent->fallOS_extent_pcp_count);
         if (CHECK_EXTENT_START(phys_addr, (extent->fallOS_extent_start))) {
                 extent->fallOS_extent_start = phys_addr;
 		extent->fallOS_virt_start = addr;
@@ -3224,12 +3207,8 @@ static fallOS_extent_t* fallOS_add_extent(struct page *page, unsigned long addr)
 	fallOS_initialize_extent(extent);
         if (!fallOS_add_page_to_extent(page, extent, addr))
 		return NULL;
-        /*printk("fallOS Following are details:\n");
-        printk("fallOS extent start addr: %lu\textent end addr: %lu\textent count: %d\ntpid: %d\n", 
-		   extent->fallOS_extent_start, extent->fallOS_extent_end, 
-		   extent->fallOS_extent_pcp_count, current->fallOS_extent);*/
 	current->fallOS_extent_count++;
-	//printk("fallOS extent count %d\n", current->fallOS_extent_count);
+	printk("fallOS extent count %d\n", current->fallOS_extent_count);
         return extent;
 }
 /*
@@ -3290,19 +3269,12 @@ static int do_anonymous_page(struct vm_fault *vmf)
 	if (unlikely(anon_vma_prepare(vma)))
 		goto oom;
 	page = alloc_zeroed_user_highpage_movable(vma, vmf->address);
-	if (current->pid == current->fallOS_extent){
-		printk("print page struct with percent p %p",page);
-		printk("print page struct with percent llu %llu",page);
-		printk("print page struct with percent d %d",page);
-		printk("print page_to_phys with percent p %p",page_to_phys(page));
-		printk("print page_to_phys with percent d %d",page_to_phys(page));
-		printk("print page_to_phys with percent llu %llu",page_to_phys(page));
-	}
 	if (!page)
 		goto oom;
 	if (current->pid == current->fallOS_extent) {
-		printk("virtual address: %lu page physical: %llu", vmf->address, virt_to_phys(page_address(page)));
-		fallOS_addto_extent_rb(&(current->fallOS_extent_rb.rb_node), page, current->fallOS_extent_rb.rb_node, vmf->address);
+		printk("fallOS virtual address: %lu page physical: %llu", vmf->address, virt_to_phys(page_address(page)));
+		if (!fallOS_addto_extent_rb(&(current->fallOS_extent_rb.rb_node), page, current->fallOS_extent_rb.rb_node, vmf->address))
+				printk("\nfallOS FAILED\n");
 	}
 	if (mem_cgroup_try_charge(page, vma->vm_mm, GFP_KERNEL, &memcg, false))
 		goto oom_free_page;
@@ -4070,7 +4042,7 @@ static int handle_pte_fault(struct vm_fault *vmf)
 	pte_t entry;
 	int index;
 	unsigned long initial_addr;
-
+	unsigned int count = 0;
 	if (unlikely(pmd_none(*vmf->pmd))) {
 		/*
 		 * Leave __pte_alloc() until later: because vm_ops->fault may
@@ -4110,9 +4082,8 @@ static int handle_pte_fault(struct vm_fault *vmf)
 		if (vma_is_anonymous(vmf->vma)) {
 			ret_code = do_anonymous_page(vmf);
 			if (current->pid == current->fallOS_extent) {
-				printk("fallOS");
 				initial_addr = vmf->address;
-				for (index = 1; index < 6; index++) {
+				for (index = 1; index < 16; index++) {
 					if (initial_addr + index * PAGE_SIZE < vmf->vma->vm_end) {
 						vmf->address = initial_addr + index * PAGE_SIZE;
 						ret_code = do_anonymous_page(vmf);
@@ -4120,14 +4091,10 @@ static int handle_pte_fault(struct vm_fault *vmf)
 				}	
 				vmf->address = initial_addr;
 			}
-			if(current->pid == current->fallOS_total_extent_count){
-		 		/* syscall to count total extent ? */
-				printk("INSIDETOTAL");
-				int total_pcp;
-				total_pcp = 0;
-				printk("Total Page Count %d", find_total_extent_count_in_fallOS(current->fallOS_extent_rb.rb_node,total_pcp));
-				printk("fallOS extent count %d\n", current->fallOS_extent_count);
-				current->fallOS_total_extent_count = 0;
+			if (current->pid == current->traverse) {
+				find_pcp_count(current->fallOS_extent_rb.rb_node, &count);
+				printk("fallOS page count %u\n", count);
+				current->traverse = 0;
 			}
 			return ret_code;
 		}
diff --git a/mm/mmap.c b/mm/mmap.c
index 95df4a976703..ecad69202bbf 100644
--- a/mm/mmap.c
+++ b/mm/mmap.c
@@ -3731,12 +3731,10 @@ asmlinkage long sys_fallos(void) {
 	return 0;
 }
 
-asmlinkage int sys_total_ext_count(void){
-
-	printk("IN SYSTOTALEXT");
+asmlinkage long sys_traverse(void) {
 	struct task_struct *tsk;
         tsk = get_current();
-        tsk->fallOS_total_extent_count = tsk->pid;
+	tsk->traverse = tsk->pid;
 	return 0;
 
 }
-- 
2.33.0

